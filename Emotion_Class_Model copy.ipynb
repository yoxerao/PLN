{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is already lowercased and lacks punctuation. We will tokenize the text and remove stopwords, as well as apply lemmatization to the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T23:03:12.958810Z",
     "start_time": "2024-03-30T23:02:16.442182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jcarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jcarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jcarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                text  label\n0  [feel, awful, job, get, position, succeed, hap...      0\n1                           [im, alone, feel, awful]      0\n2  [ive, probably, mentioned, really, feel, proud...      1\n3                  [feeling, little, low, day, back]      0\n4  [beleive, much, sensitive, people, feeling, te...      2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[feel, awful, job, get, position, succeed, hap...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[im, alone, feel, awful]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[ive, probably, mentioned, really, feel, proud...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[feeling, little, low, day, back]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[beleive, much, sensitive, people, feeling, te...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "data = pd.read_json('./data/data.jsonl', lines=True)\n",
    "def pre_process_data(dataset):\n",
    "    #tokenize\n",
    "    dataset['text'] = dataset['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "    #remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    dataset['text'] = dataset['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    #lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    dataset['text'] = dataset['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "data = pre_process_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T23:03:19.149553Z",
     "start_time": "2024-03-30T23:03:16.785265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [im, feeling, rather, rotten, im, ambitious, r...\n",
      "1                      [im, updating, blog, feel, shitty]\n",
      "2       [never, make, separate, ever, want, feel, like...\n",
      "3       [left, bouquet, red, yellow, tulip, arm, feeli...\n",
      "4                            [feeling, little, vain, one]\n",
      "                              ...                        \n",
      "1995    [keep, feeling, like, someone, unkind, wrong, ...\n",
      "1996    [im, feeling, little, cranky, negative, doctor...\n",
      "1997    [feel, useful, people, give, great, feeling, a...\n",
      "1998    [im, feeling, comfortable, derby, feel, though...\n",
      "1999    [feel, weird, meet, w, people, text, like, don...\n",
      "Name: text, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json('./data/test.jsonl', lines=True)\n",
    "train_data = pd.read_json('./data/train.jsonl', lines=True)\n",
    "validation_data = pd.read_json('./data/validation.jsonl', lines=True)\n",
    "\n",
    "test_data = pre_process_data(test_data)\n",
    "train_data = pre_process_data(train_data)\n",
    "validation_data = pre_process_data(validation_data)\n",
    "\n",
    "print(test_data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Vectorization\n",
    "(secção possívelmente temporária, mas queria experimentar as cenas de tf_idf depois do pré-processamento) -- matos\n",
    "não acho que convenha ser temporaria, dado que efetivamente melhora os resultados ihihihi, e é uma prática comum e recomendada pelo que estivemos a ver -- ines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertunning for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T23:03:23.009252Z",
     "start_time": "2024-03-30T23:03:23.002457Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidfVectorizer(data, train_data, validation_data, test_data):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=40000)\n",
    "    # good idea to use two-grams??\n",
    "    # print(X.shape)\n",
    "\n",
    "    x_train = vectorizer.fit_transform(train_data['text'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "    x_val = vectorizer.transform(validation_data['text'].apply(lambda x: ' '.join(x)))\n",
    "    x_test = vectorizer.transform(test_data['text'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "    y_train = train_data['label']\n",
    "    y_val = validation_data['label']\n",
    "    y_test = test_data['label']\n",
    "    \n",
    "    # print(vectorizer.get_feature_names_out())\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW model\n",
    "Count vectorizer which is an implementation of the BOW model.\n",
    "\n",
    "The disadvantage of the BOW model is it does not consider the sequence of words, and as language does involve sequence and context, sometimes the BOW model might not be a good fit for the best-case scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T23:03:25.830070Z",
     "start_time": "2024-03-30T23:03:25.823498Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def countVectorizer(data, train_data, validation_data, test_data):\n",
    "    # Initialize CountVectorizer\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=40000)\n",
    "\n",
    "    x_train= vectorizer.fit_transform(train_data['text'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "    x_val = vectorizer.transform(validation_data['text'].apply(lambda x: ' '.join(x)))\n",
    "    x_test = vectorizer.transform(test_data['text'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "    y_train = train_data['label']\n",
    "    y_val = validation_data['label']\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc 2 Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document 2 Vector training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T23:03:50.818046Z",
     "start_time": "2024-03-30T23:03:28.048219Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 26\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel Saved\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[1;32m---> 26\u001B[0m \u001B[43mtrain_doc2vec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 19\u001B[0m, in \u001B[0;36mtrain_doc2vec\u001B[1;34m(train_data)\u001B[0m\n\u001B[0;32m     11\u001B[0m model \u001B[38;5;241m=\u001B[39m Doc2Vec(vector_size\u001B[38;5;241m=\u001B[39mvec_size,\n\u001B[0;32m     12\u001B[0m                 alpha\u001B[38;5;241m=\u001B[39malpha,\n\u001B[0;32m     13\u001B[0m                 min_alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00025\u001B[39m,\n\u001B[0;32m     14\u001B[0m                 min_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     15\u001B[0m                 dm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     17\u001B[0m model\u001B[38;5;241m.\u001B[39mbuild_vocab(tagged_data)\n\u001B[1;32m---> 19\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtagged_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorpus_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39mepochs)\n\u001B[0;32m     21\u001B[0m model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124md2v_v50.model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\site-packages\\gensim\\models\\doc2vec.py:516\u001B[0m, in \u001B[0;36mDoc2Vec.train\u001B[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    513\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moffsets\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m offsets\n\u001B[0;32m    514\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstart_doctags\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m start_doctags\n\u001B[1;32m--> 516\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mDoc2Vec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus_iterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_examples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_alpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_alpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_alpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend_alpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mword_count\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqueue_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueue_factor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport_delay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreport_delay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\site-packages\\gensim\\models\\word2vec.py:1073\u001B[0m, in \u001B[0;36mWord2Vec.train\u001B[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m   1070\u001B[0m     callback\u001B[38;5;241m.\u001B[39mon_epoch_begin(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1072\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m corpus_iterable \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1073\u001B[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1074\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcur_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcur_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_examples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1075\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqueue_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueue_factor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport_delay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreport_delay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1076\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1078\u001B[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_epoch_corpusfile(\n\u001B[0;32m   1079\u001B[0m         corpus_file, cur_epoch\u001B[38;5;241m=\u001B[39mcur_epoch, total_examples\u001B[38;5;241m=\u001B[39mtotal_examples, total_words\u001B[38;5;241m=\u001B[39mtotal_words,\n\u001B[0;32m   1080\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\site-packages\\gensim\\models\\word2vec.py:1434\u001B[0m, in \u001B[0;36mWord2Vec._train_epoch\u001B[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001B[0m\n\u001B[0;32m   1431\u001B[0m     thread\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# make interrupting the process with ctrl+c easier\u001B[39;00m\n\u001B[0;32m   1432\u001B[0m     thread\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m-> 1434\u001B[0m trained_word_count, raw_word_count, job_tally \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_epoch_progress\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1435\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprogress_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcur_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcur_epoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_examples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport_delay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreport_delay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_corpus_file_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1437\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1439\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\site-packages\\gensim\\models\\word2vec.py:1289\u001B[0m, in \u001B[0;36mWord2Vec._log_epoch_progress\u001B[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001B[0m\n\u001B[0;32m   1286\u001B[0m unfinished_worker_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkers\n\u001B[0;32m   1288\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m unfinished_worker_count \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1289\u001B[0m     report \u001B[38;5;241m=\u001B[39m \u001B[43mprogress_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# blocks if workers too slow\u001B[39;00m\n\u001B[0;32m   1290\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m report \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# a thread reporting that it finished\u001B[39;00m\n\u001B[0;32m   1291\u001B[0m         unfinished_worker_count \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\queue.py:171\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qsize():\n\u001B[1;32m--> 171\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be a non-negative number\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn import utils\n",
    "\n",
    "def train_doc2vec(train_data):\n",
    "    max_epochs = 100\n",
    "    vec_size = 20\n",
    "    alpha = 0.025\n",
    "\n",
    "    tagged_data = [TaggedDocument(words=doc, tags=[str(label)]) for doc, label in zip(train_data['text'], train_data['label'])]\n",
    "\n",
    "    model = Doc2Vec(vector_size=vec_size,\n",
    "                    alpha=alpha,\n",
    "                    min_alpha=0.00025,\n",
    "                    min_count=1,\n",
    "                    dm=1)\n",
    "    \n",
    "    model.build_vocab(tagged_data)\n",
    "\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=50)\n",
    "    print(model.epochs)\n",
    "    model.save(\"d2v_v50.model\")\n",
    "    print(\"Model Saved\")\n",
    "\n",
    "    return model\n",
    "\n",
    "train_doc2vec(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T23:03:56.088025Z",
     "start_time": "2024-03-30T23:03:56.081508Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn import utils\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "def doc2vec(data, train_data, validation_data, test_data):\n",
    "\n",
    "    # training the doc2vec model\n",
    "    #model = train_doc2vec(train_data)\n",
    "    model = Doc2Vec.load(\"d2v_v3.model\")\n",
    "    \n",
    "    x_train = [model.infer_vector(doc) for doc in train_data['text']]\n",
    "    x_val = [model.infer_vector(doc) for doc in validation_data['text']]\n",
    "    x_test = [model.infer_vector(doc) for doc in test_data['text']]\n",
    "\n",
    "    y_train = train_data['label']\n",
    "    y_val = validation_data['label']\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word 2 Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T23:03:59.623710Z",
     "start_time": "2024-03-30T23:03:59.617658Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "def lala(model, data):\n",
    "    vectors = []\n",
    "    for doc in data['text']:\n",
    "        document = []\n",
    "        for word in doc:\n",
    "            if word in model.wv:\n",
    "                document.append(model.wv[word])\n",
    "        vectors.append(document)\n",
    "    return vectors\n",
    "\n",
    "# test [d,c,c]  | label\n",
    "########################\n",
    "## test \n",
    "## [ [] [] [] ] | label\n",
    "\n",
    "def wordEmbeddingsVectorizer(data):\n",
    "\n",
    "    data_model = Word2Vec(data[\"text\"], vector_size=3, window=10, min_count=2, workers=10, sg=1)\n",
    "    \n",
    "    x_train = lala(data_model, train_data)\n",
    "    x_val =lala(data_model, validation_data)\n",
    "    x_test = lala(data_model, test_data)\n",
    "\n",
    "    y_train = train_data['label']\n",
    "    y_val = validation_data['label']\n",
    "    y_test = test_data['label']\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T23:04:10.896144Z",
     "start_time": "2024-03-30T23:04:02.653906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose vectorizer (featurizer)\n",
    "#x_train, x_val, x_test, y_train, y_val, y_test = tfidfVectorizer(data, train_data, validation_data, test_data)\n",
    "#x_train, x_val, x_test, y_train, y_val, y_test = countVectorizer(data, train_data, validation_data, test_data)\n",
    "#x_train, x_val, x_test, y_train, y_val, y_test = wordEmbeddingsVectorizer(data)\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = doc2vec(data, train_data, validation_data, test_data)\n",
    "\n",
    "#print(x_train)\n",
    "\n",
    "## Apply SMOTE\n",
    "smote = SMOTE(random_state=42, sampling_strategy='auto', k_neighbors=10)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3.1. Model Selection\n",
    "Aqui também só estava a querer espetar modelos para começar a ver o que dá que ainda não sei que features vão ser usadas:\n",
    "tf-idf, word embeddings, ???, features mais feitas à mão?\n",
    "\n",
    "\n",
    "Isto pelos vistos é uma cena, que não implementei (ainda..)\n",
    "\n",
    "\"The validation set uses a subset of the training data to provide an unbiased evaluation of a model. The validation data set contrasts with training and test sets in that it is an intermediate phase used for choosing the best model and optimizing it. It is in this phase that hyperparameter tuning occurs.\"\n",
    "\n",
    "Wikipedia:\n",
    "The basic process of using a validation data set for model selection (as part of training data set, validation data set, and test data set) is:\n",
    "\n",
    "Since our goal is to find the network having the best performance on new data, the simplest approach to the comparison of different networks is to evaluate the error function using data which is independent of that used for training. Various networks are trained by minimization of an appropriate error function defined with respect to a training data set. The performance of the networks is then compared by evaluating the error function using an independent validation set, and the network having the smallest error with respect to the validation set is selected. This approach is called the hold out method. Since this procedure can itself lead to some overfitting to the validation set, the performance of the selected network should be confirmed by measuring its performance on a third independent set of data called a test set.\n",
    "\n",
    "An application of this process is in early stopping, where the candidate models are successive iterations of the same network, and training stops when the error on the validation set grows, choosing the previous model (the one with minimum error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 3.1.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T23:04:18.887869Z",
     "start_time": "2024-03-30T23:04:16.951468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       550\n",
      "           1       0.90      0.84      0.87       704\n",
      "           2       0.72      0.76      0.74       178\n",
      "           3       0.79      0.80      0.80       275\n",
      "           4       0.73      0.80      0.76       212\n",
      "           5       0.68      0.78      0.73        81\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.78      0.81      0.79      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n",
      "[[476  18   5  25  22   4]\n",
      " [ 32 590  43  15  17   7]\n",
      " [ 10  21 135   9   2   1]\n",
      " [ 19  15   3 220  15   3]\n",
      " [ 14   5   2   8 169  14]\n",
      " [  6   7   0   0   5  63]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "logreg_classifier = LogisticRegression(max_iter=1000)\n",
    "logreg_classifier.fit(x_train, y_train)\n",
    "y_pred = logreg_classifier.predict(x_val)\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 3.1.2. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:25:04.605149100Z",
     "start_time": "2024-03-12T21:25:04.576734900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[73], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m mnb_classifier \u001B[38;5;241m=\u001B[39m MultinomialNB()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmnb_classifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m mnb_classifier\u001B[38;5;241m.\u001B[39mpredict(x_val)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(accuracy_score(y_val, y_pred))\n",
      "File \u001B[1;32mc:\\Users\\inesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:776\u001B[0m, in \u001B[0;36m_BaseDiscreteNB.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    774\u001B[0m n_classes \u001B[38;5;241m=\u001B[39m Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_counters(n_classes, n_features)\n\u001B[1;32m--> 776\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_count\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    777\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_alpha()\n\u001B[0;32m    778\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_feature_log_prob(alpha)\n",
      "File \u001B[1;32mc:\\Users\\inesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:898\u001B[0m, in \u001B[0;36mMultinomialNB._count\u001B[1;34m(self, X, Y)\u001B[0m\n\u001B[0;32m    896\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_count\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, Y):\n\u001B[0;32m    897\u001B[0m     \u001B[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 898\u001B[0m     \u001B[43mcheck_non_negative\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMultinomialNB (input X)\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_count_ \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m safe_sparse_dot(Y\u001B[38;5;241m.\u001B[39mT, X)\n\u001B[0;32m    900\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_count_ \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m Y\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mc:\\Users\\inesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1418\u001B[0m, in \u001B[0;36mcheck_non_negative\u001B[1;34m(X, whom)\u001B[0m\n\u001B[0;32m   1415\u001B[0m     X_min \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mmin(X)\n\u001B[0;32m   1417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X_min \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1418\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNegative values in data passed to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m whom)\n",
      "\u001B[1;31mValueError\u001B[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "\n",
    "mnb_classifier = MultinomialNB()\n",
    "mnb_classifier.fit(x_train, y_train)\n",
    "y_pred = mnb_classifier.predict(x_val)\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "y_pred = svm_classifier.predict(x_val)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7845\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       550\n",
      "           1       0.89      0.80      0.84       704\n",
      "           2       0.63      0.75      0.69       178\n",
      "           3       0.71      0.75      0.73       275\n",
      "           4       0.69      0.77      0.73       212\n",
      "           5       0.65      0.77      0.70        81\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.73      0.77      0.75      2000\n",
      "weighted avg       0.79      0.78      0.79      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[442  20  10  43  29   6]\n",
      " [ 32 562  60  20  20  10]\n",
      " [ 15  19 134   8   2   0]\n",
      " [ 25  15   7 205  19   4]\n",
      " [ 12  11   1  11 164  13]\n",
      " [  6   7   1   1   4  62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "y_pred = knn_classifier.predict(x_val)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T23:05:25.538501Z",
     "start_time": "2024-03-30T23:05:23.494804Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.026830490678548813, -0.019013537093997, -0.059499457478523254, 0.06124862655997276, 0.04711579531431198, -0.006191493943333626, -0.0326736681163311, -0.005408844910562038, -0.09011674672365189, 0.0013511104043573141, 0.025126906111836433, -0.009618275798857212, -0.059388745576143265, 0.024362312629818916, -0.0134808998554945, -0.044539522379636765, 0.03504060208797455, 0.03904849290847778, -0.07437518239021301, -0.03468192368745804]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T23:06:38.033286Z",
     "start_time": "2024-03-30T23:06:38.028209Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Algorithms\n",
    "\n",
    "Testing with some boosting algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Evaluation:\n",
      "Accuracy: 0.592\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       550\n",
      "           1       0.64      0.76      0.69       704\n",
      "           2       0.45      0.36      0.40       178\n",
      "           3       0.56      0.45      0.50       275\n",
      "           4       0.47      0.42      0.44       212\n",
      "           5       0.43      0.35      0.38        81\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.53      0.49      0.51      2000\n",
      "weighted avg       0.58      0.59      0.58      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[344 104  18  43  36   5]\n",
      " [ 79 535  39  15  26  10]\n",
      " [ 25  59  64  14  10   6]\n",
      " [ 54  60   7 124  20  10]\n",
      " [ 32  55   9  21  89   6]\n",
      " [ 11  23   5   4  10  28]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# XGBoost Classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred_xgb = xgb_classifier.predict(x_val)\n",
    "\n",
    "# Evaluate the performance for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_val, y_pred_xgb)\n",
    "report_xgb = classification_report(y_val, y_pred_xgb)\n",
    "conf_matrix_xgb = confusion_matrix(y_val, y_pred_xgb)\n",
    "\n",
    "# Print the evaluation metrics for XGBoost\n",
    "print(\"XGBoost Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(\"Classification Report:\\n\", report_xgb)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 32172, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "\n",
      "LightGBM Classifier Evaluation:\n",
      "Accuracy: 0.587\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.63       550\n",
      "           1       0.67      0.72      0.69       704\n",
      "           2       0.44      0.43      0.44       178\n",
      "           3       0.50      0.42      0.45       275\n",
      "           4       0.46      0.46      0.46       212\n",
      "           5       0.45      0.42      0.44        81\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.52      0.51      0.52      2000\n",
      "weighted avg       0.58      0.59      0.58      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[342  88  24  48  40   8]\n",
      " [ 83 508  42  27  29  15]\n",
      " [ 24  45  77  19   9   4]\n",
      " [ 50  56  14 115  31   9]\n",
      " [ 36  44  11  18  98   5]\n",
      " [  7  21   6   5   8  34]]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_classifier = lgb.LGBMClassifier()\n",
    "lgb_classifier.fit(x_train, y_train)\n",
    "y_pred_lgb = lgb_classifier.predict(x_val)\n",
    "\n",
    "# Evaluate the performance for LightGBM\n",
    "accuracy_lgb = accuracy_score(y_val, y_pred_lgb)\n",
    "report_lgb = classification_report(y_val, y_pred_lgb)\n",
    "conf_matrix_lgb = confusion_matrix(y_val, y_pred_lgb)\n",
    "\n",
    "# Print the evaluation metrics for LightGBM\n",
    "print(\"\\nLightGBM Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_lgb)\n",
    "print(\"Classification Report:\\n\", report_lgb)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Evaluation:\n",
      "Accuracy: 0.5015\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.53       550\n",
      "           1       0.66      0.61      0.63       704\n",
      "           2       0.32      0.47      0.38       178\n",
      "           3       0.45      0.39      0.42       275\n",
      "           4       0.33      0.44      0.38       212\n",
      "           5       0.22      0.40      0.28        81\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.43      0.46      0.44      2000\n",
      "weighted avg       0.54      0.50      0.51      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[259  84  43  60  70  34]\n",
      " [ 73 427  82  36  50  36]\n",
      " [ 17  42  83  12  17   7]\n",
      " [ 34  40  30 108  42  21]\n",
      " [ 29  35  15  21  94  18]\n",
      " [  9  18  10   3   9  32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# AdaBoost Classifier\n",
    "adaboost_classifier = AdaBoostClassifier()\n",
    "adaboost_classifier.fit(x_train, y_train)\n",
    "y_pred_adaboost = adaboost_classifier.predict(x_val)\n",
    "\n",
    "# Evaluate the performance for AdaBoost\n",
    "accuracy_adaboost = accuracy_score(y_val, y_pred_adaboost)\n",
    "report_adaboost = classification_report(y_val, y_pred_adaboost)\n",
    "conf_matrix_adaboost = confusion_matrix(y_val, y_pred_adaboost)\n",
    "\n",
    "# Print the evaluation metrics for AdaBoost\n",
    "print(\"AdaBoost Classifier Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_adaboost)\n",
    "print(\"Classification Report:\\n\", report_adaboost)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_adaboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bagging Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:26:00.951289100Z",
     "start_time": "2024-03-12T21:26:00.934288300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67       581\n",
      "           1       0.76      0.56      0.64       695\n",
      "           2       0.30      0.53      0.39       159\n",
      "           3       0.48      0.48      0.48       275\n",
      "           4       0.44      0.54      0.48       224\n",
      "           5       0.22      0.65      0.33        66\n",
      "\n",
      "    accuracy                           0.56      2000\n",
      "   macro avg       0.49      0.56      0.50      2000\n",
      "weighted avg       0.63      0.56      0.58      2000\n",
      "\n",
      "[[351  50  43  44  55  38]\n",
      " [ 55 386  98  55  53  48]\n",
      " [  9  25  84  14  17  10]\n",
      " [ 36  26  29 132  24  28]\n",
      " [ 17  17  17  26 121  26]\n",
      " [  3   4   6   5   5  43]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate with test set\n",
    "y_pred = logreg_classifier.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T21:26:02.675927800Z",
     "start_time": "2024-03-12T21:26:02.644922100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90       581\n",
      "           1       0.86      0.91      0.88       695\n",
      "           2       0.74      0.65      0.69       159\n",
      "           3       0.88      0.77      0.82       275\n",
      "           4       0.89      0.79      0.83       224\n",
      "           5       0.76      0.59      0.67        66\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.83      0.77      0.80      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "[[542  15   1  13   9   1]\n",
      " [ 15 633  35   3   4   5]\n",
      " [ 11  40 104   4   0   0]\n",
      " [ 29  29   1 211   5   0]\n",
      " [ 23  11   0   7 177   6]\n",
      " [  9  12   0   1   5  39]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = mnb_classifier.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       581\n",
      "           1       0.76      0.57      0.65       695\n",
      "           2       0.32      0.54      0.40       159\n",
      "           3       0.50      0.49      0.49       275\n",
      "           4       0.45      0.55      0.49       224\n",
      "           5       0.23      0.62      0.33        66\n",
      "\n",
      "    accuracy                           0.57      2000\n",
      "   macro avg       0.50      0.57      0.51      2000\n",
      "weighted avg       0.63      0.57      0.59      2000\n",
      "\n",
      "[[361  52  43  41  53  31]\n",
      " [ 57 397  94  48  52  47]\n",
      " [  8  26  86  13  16  10]\n",
      " [ 36  25  27 134  27  26]\n",
      " [ 16  19  15  26 123  25]\n",
      " [  3   5   7   5   5  41]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_classifier.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       581\n",
      "           1       0.63      0.70      0.67       695\n",
      "           2       0.39      0.33      0.36       159\n",
      "           3       0.54      0.41      0.47       275\n",
      "           4       0.47      0.43      0.45       224\n",
      "           5       0.41      0.44      0.43        66\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.51      0.50      0.50      2000\n",
      "weighted avg       0.58      0.58      0.58      2000\n",
      "\n",
      "[[389 107  14  26  39   6]\n",
      " [ 88 489  39  37  29  13]\n",
      " [ 22  57  52  13  10   5]\n",
      " [ 58  53  15 114  27   8]\n",
      " [ 39  55   7  17  97   9]\n",
      " [  7  14   6   4   6  29]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_classifier.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       581\n",
      "           1       0.65      0.71      0.68       695\n",
      "           2       0.41      0.40      0.41       159\n",
      "           3       0.51      0.42      0.46       275\n",
      "           4       0.48      0.48      0.48       224\n",
      "           5       0.42      0.45      0.43        66\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.52      0.52      0.52      2000\n",
      "weighted avg       0.59      0.60      0.59      2000\n",
      "\n",
      "[[383  93  21  37  41   6]\n",
      " [ 78 492  40  37  35  13]\n",
      " [ 19  45  64  15  12   4]\n",
      " [ 48  61  16 116  25   9]\n",
      " [ 27  50  10  20 107  10]\n",
      " [ 11  13   5   4   3  30]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_classifier.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.48      0.55       581\n",
      "           1       0.63      0.55      0.59       695\n",
      "           2       0.25      0.47      0.33       159\n",
      "           3       0.46      0.37      0.41       275\n",
      "           4       0.33      0.44      0.38       224\n",
      "           5       0.20      0.47      0.28        66\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.42      0.46      0.42      2000\n",
      "weighted avg       0.54      0.48      0.50      2000\n",
      "\n",
      "[[278  98  57  44  70  34]\n",
      " [ 68 380  94  44  66  43]\n",
      " [  9  35  75  14  18   8]\n",
      " [ 30  40  38 103  38  26]\n",
      " [ 30  38  23  19  98  16]\n",
      " [  9   9   8   2   7  31]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = adaboost_classifier.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cause of errors"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
