{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction import text\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "data = pd.read_json('../data/data.jsonl', lines=True)\n",
    "test_data = pd.read_json('../data/test_final.jsonl', lines=True)\n",
    "train_data = pd.read_json('../data/train_final.jsonl', lines=True)\n",
    "validation_data = pd.read_json('../data/validation_final.jsonl', lines=True)\n",
    "\n",
    "# Remove duplicates\n",
    "test_data = test_data.drop_duplicates(subset=['text'])\n",
    "train_data = train_data.drop_duplicates(subset=['text'])\n",
    "validation_data = validation_data.drop_duplicates(subset=['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['woke', 'feeling', 'particularly', 'vile', 'tried', 'ignore', 'but', 'got', 'worse', 'worse', 'worse']\n",
      "0       [feel, awful, s, job, position, succeed, just,...\n",
      "1                                [im, alone, feel, awful]\n",
      "2       [ive, probably, mentioned, but, really, feel, ...\n",
      "3                             [feeling, little, low, day]\n",
      "4       [beleive, sensitive, people, feeling, tend, co...\n",
      "                              ...                        \n",
      "5395              [feel, grumpy, haven, t, yoga, ed, day]\n",
      "5396    [read, blog, suburb, direction, mentioned, cas...\n",
      "5397    [not, feel, thing, realize, violent, physical,...\n",
      "5398    [feel, petty, silly, giving, shit, but, little...\n",
      "5399    [remember, feeling, bitter, couldnt, pop, ball...\n",
      "Name: text, Length: 5396, dtype: object\n"
     ]
    }
   ],
   "source": [
    "my_stop_words = text.ENGLISH_STOP_WORDS\n",
    "words_to_keep = frozenset(['no', 'couldnt', 'cry', 'not', 'cant', 'cannot', 'nor', 'except', 'nobody',\n",
    "                           'off', 'but', 'serious', 'enough', 'nothing', 'alone', 'down', 'only', 'without'])\n",
    "my_stop_words = my_stop_words - words_to_keep\n",
    "\n",
    "def pre_process_data(dataset):\n",
    "    # Tokenize\n",
    "    dataset['text'] = dataset['text'].apply(word_tokenize)\n",
    "    # Remove stop words\n",
    "    dataset['text'] = dataset['text'].apply(lambda x: [word for word in x if word.lower() not in my_stop_words])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_data = pre_process_data(train_data)\n",
    "validation_data = pre_process_data(validation_data)\n",
    "test_data = pre_process_data(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization Using BERT Tokenizer:\n",
    "BERT tokenizer requires the data to be in a specific format\n",
    "\n",
    "???????? MAS ESTÁ CERTO ANTES TAMBEM TOKENIZARMOS ????????\n",
    "\n",
    "\n",
    "* podemos usar o bert-base-uncased e o roberta-based e comparar dps\n",
    "* maybe usar embeddings tb depois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\inesc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# SUPOSTAMENTE ESTE TB É BOM\n",
    "# model_name = \"roberta-base\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "\n",
    "# Tokenize using BERT tokenizer\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(texts, padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "train_encodings = tokenize_data(train_data['text'].apply(lambda x: ' '.join(x)).tolist())\n",
    "val_encodings = tokenize_data(validation_data['text'].apply(lambda x: ' '.join(x)).tolist())\n",
    "test_encodings = tokenize_data(test_data['text'].apply(lambda x: ' '.join(x)).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, train_data['label'].tolist())\n",
    "val_dataset = TextDataset(val_encodings, validation_data['label'].tolist())\n",
    "test_dataset = TextDataset(test_encodings, test_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training hyppertunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## depois coloco aqui quando passar o trainer parar de me dar erro ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,\n",
    "##    per_device_train_batch_size=8,\n",
    "##     per_device_eval_batch_size=8,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     logging_dir='./logs',\n",
    "# )\n",
    "\n",
    "# # Initialize Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n",
    "# eval_results = trainer.evaluate()\n",
    "# print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = trainer.predict(test_dataset)\n",
    "# preds = np.argmax(predictions.predictions, axis=1)\n",
    "# print(preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
