{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:44:01.741794Z",
     "start_time": "2024-05-19T13:43:36.366892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jcarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jcarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jcarv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from datasets import DatasetDict\n",
    "from sklearn.feature_extraction import text\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "from transformers import TrainerCallback\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:44:30.963593Z",
     "start_time": "2024-05-19T13:44:30.949593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! \n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! \")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    \n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:44:36.035734Z",
     "start_time": "2024-05-19T13:44:34.241384Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_json('../data/data.jsonl', lines=True)\n",
    "test_data = pd.read_json('../data/test_final.jsonl', lines=True)\n",
    "train_data = pd.read_json('../data/train_final.jsonl', lines=True)\n",
    "validation_data = pd.read_json('../data/validation_final.jsonl', lines=True)\n",
    "\n",
    "# Remove duplicates\n",
    "test_data = test_data.drop_duplicates(subset=['text'])\n",
    "train_data = train_data.drop_duplicates(subset=['text'])\n",
    "validation_data = validation_data.drop_duplicates(subset=['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:44:49.971469Z",
     "start_time": "2024-05-19T13:44:43.997435Z"
    }
   },
   "outputs": [],
   "source": [
    "my_stop_words = text.ENGLISH_STOP_WORDS\n",
    "words_to_keep = frozenset(['no', 'couldnt', 'cry', 'not', 'cant', 'cannot', 'nor', 'except', 'nobody',\n",
    "                           'off', 'but', 'serious', 'enough', 'nothing', 'alone', 'down', 'only', 'without'])\n",
    "my_stop_words = my_stop_words - words_to_keep\n",
    "\n",
    "def pre_process_data(dataset):\n",
    "    # Remove stop words\n",
    "    dataset['text'] = dataset['text'].apply(\n",
    "        lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in my_stop_words])\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_data = pre_process_data(train_data)\n",
    "validation_data = pre_process_data(validation_data)\n",
    "test_data = pre_process_data(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization Using pre-trained model Tokenizer:\n",
    "The model tokenizer requires the data to be in a specific format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T03:59:57.778313Z",
     "start_time": "2024-05-19T03:59:50.089792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model tokenizer and model\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "# model_name = \"distilbert-base-uncased\"\n",
    "# model_name = \"roberta-base\"\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6).to(device)\n",
    "\n",
    "# Tokenize using BERT tokenizer\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(texts, padding='max_length', return_tensors='pt', truncation=True, max_length=128).to(device)\n",
    "\n",
    "train_encodings = tokenize_data(train_data['text'].apply(lambda x: ' '.join(x)).tolist())\n",
    "val_encodings = tokenize_data(validation_data['text'].apply(lambda x: ' '.join(x)).tolist())\n",
    "test_encodings = tokenize_data(test_data['text'].apply(lambda x: ' '.join(x)).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:00:02.545984Z",
     "start_time": "2024-05-19T04:00:02.526199Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset: TextDataset = TextDataset(train_encodings, train_data['label'].tolist())\n",
    "val_dataset: TextDataset = TextDataset(val_encodings, validation_data['label'].tolist())\n",
    "test_dataset: TextDataset = TextDataset(test_encodings, test_data['label'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute the training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:00:04.600299Z",
     "start_time": "2024-05-19T04:00:04.587757Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that saves the training stats of the model to a file for further comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T04:00:06.709202Z",
     "start_time": "2024-05-19T04:00:06.701674Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainingStatsCallback(TrainerCallback):\n",
    "    \"\"\"A callback that logs and stores the progress of training.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics_df = pd.DataFrame()\n",
    "        self.output_dir = './training_stats'\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # Assuming `metrics` is passed as part of kwargs and is a dictionary\n",
    "        metrics = kwargs.get('metrics')\n",
    "        new_record = pd.DataFrame([metrics])\n",
    "        self.metrics_df = pd.concat([self.metrics_df, new_record], ignore_index=True)\n",
    "        self.metrics_df.to_csv(os.path.join(self.output_dir, 'metrics.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training hyppertunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# def model_init():\n",
    "#     return AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Hyperparameters to tune\n",
    "#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "#     num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 5)\n",
    "#     per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32])\n",
    "    \n",
    "#     # Define TrainingArguments with hyperparameters from the trial\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=\"./results\",\n",
    "#         learning_rate=learning_rate,\n",
    "#         per_device_train_batch_size=per_device_train_batch_size,\n",
    "#         num_train_epochs=num_train_epochs,\n",
    "#         weight_decay=0.01,\n",
    "#         evaluation_strategy=\"epoch\",\n",
    "#         save_strategy=\"epoch\",\n",
    "#         load_best_model_at_end=True,\n",
    "#         metric_for_best_model=\"accuracy\",\n",
    "#     )\n",
    "    \n",
    "#     trainer = Trainer(\n",
    "#         model_init=model_init,\n",
    "#         args=training_args,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=val_dataset,\n",
    "#         tokenizer=tokenizer,\n",
    "#         compute_metrics=compute_metrics\n",
    "#     )\n",
    "    \n",
    "#     trainer.train()\n",
    "#     eval_result = trainer.evaluate()\n",
    "    \n",
    "#     # Optuna aims to minimize the objective, so if accuracy is the metric, return 1 - accuracy\n",
    "#     return 1 - eval_result[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(objective, n_trials=20)\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# trial_ = study.best_trial\n",
    "\n",
    "# print(f\"  Value: {trial_.value}\")\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial_.params.items():\n",
    "#     print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels range:  0 to 5\n",
      "Validation labels range:  0 to 5\n",
      "Test labels range:  0 to 5\n",
      "Training data NaN values: False\n",
      "Validation data NaN values: False\n",
      "Test data NaN values: False\n",
      "<transformers.trainer.Trainer object at 0x00000209D1B430D0>\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "print(\"Training labels range: \", min(train_data['label']), \"to\", max(train_data['label']))\n",
    "print(\"Validation labels range: \", min(validation_data['label']), \"to\", max(validation_data['label']))\n",
    "print(\"Test labels range: \", min(test_data['label']), \"to\", max(test_data['label']))\n",
    "\n",
    "print(\"Training data NaN values:\", train_data.isnull().values.any())\n",
    "print(\"Validation data NaN values:\", validation_data.isnull().values.any())\n",
    "print(\"Test data NaN values:\", test_data.isnull().values.any())\n",
    "\n",
    " # Initialize Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[TrainingStatsCallback]\n",
    ")\n",
    "\n",
    "print(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "  2%|▏         | 500/21304 [11:07<7:40:03,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7966, 'grad_norm': 1.9971829652786255, 'learning_rate': 1.9530604581299287e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  5%|▍         | 1000/21304 [22:07<7:32:30,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7285, 'grad_norm': 5.741614818572998, 'learning_rate': 1.9061209162598577e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "  7%|▋         | 1500/21304 [33:16<7:17:21,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4968, 'grad_norm': 5.530463695526123, 'learning_rate': 1.8591813743897863e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1909/21304 [42:33<7:43:33,  1.43s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_path = f'./my_trained_models/{model_name}'\n",
    "trainer.save_model(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:03:59.057362Z",
     "start_time": "2024-05-17T09:03:58.620375Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Domain adaptation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForMaskedLM(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BertOnlyMLMHead(\n    (predictions): BertLMPredictionHead(\n      (transform): BertPredictionHeadTransform(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (transform_act_fn): GELUActivation()\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "model_m = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model_m.to(device)\n",
    "\n",
    "initial_model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)  # for comparisons\n",
    "initial_model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:21:18.204012Z",
     "start_time": "2024-05-19T17:21:13.835981Z"
    }
   },
   "execution_count": 316
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:21:28.028405Z",
     "start_time": "2024-05-19T17:21:27.738097Z"
    }
   },
   "execution_count": 318
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> I am feeling weird right now, because of the weather.'\n",
      "'>>> I am feeling strange right now, because of the weather.'\n",
      "'>>> I am feeling better right now, because of the weather.'\n",
      "'>>> I am feeling bad right now, because of the weather.'\n",
      "'>>> I am feeling uncomfortable right now, because of the weather.'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "text = \"I am feeling [MASK] right now, because of the weather.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "token_logits = model_m(**inputs).logits\n",
    "# Find the location of [MASK] and extract its logits\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "# Pick the [MASK] candidates with the highest logits\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T15:49:15.565602Z",
     "start_time": "2024-05-19T15:49:15.328768Z"
    }
   },
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_data),\n",
    "    \"validation\": Dataset.from_pandas(validation_data),\n",
    "    \"test\": Dataset.from_pandas(test_data)\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:22:01.712259Z",
     "start_time": "2024-05-19T17:22:01.577269Z"
    }
   },
   "execution_count": 319
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/42607 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48869d137bb94406b6658d4c36b541a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/5398 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbfdeed207d848d29afcc5c4a14757c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/5396 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8360e539649d4fd785620d2a3c779ef4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n        num_rows: 42607\n    })\n    validation: Dataset({\n        features: ['__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n        num_rows: 5398\n    })\n    test: Dataset({\n        features: ['__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n        num_rows: 5396\n    })\n})"
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    # result = tokenizer(examples[\"text\"], padding=True, truncation=True, return_tensors='pt').to(device)  \n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
    ")\n",
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:22:07.726906Z",
     "start_time": "2024-05-19T17:22:03.330555Z"
    }
   },
   "execution_count": 320
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "512"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T13:48:10.043306Z",
     "start_time": "2024-05-19T13:48:10.032310Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chunk_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:22:44.380274Z",
     "start_time": "2024-05-19T17:22:44.363220Z"
    }
   },
   "execution_count": 321
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()\n",
    "                             if k != '__index_level_0__'}\n",
    "    \n",
    "    concatenated_examples['__index_level_0__'] = examples['__index_level_0__']\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:22:58.098113Z",
     "start_time": "2024-05-19T17:22:58.079867Z"
    }
   },
   "execution_count": 322
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/42607 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cb8ee32b72545d3871c56ccd48eded8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/5398 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c319ce3db35b44feadbec0e9ff8b4c07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/5396 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ffe41ae94214ecabddce040db82e08e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 1320\n    })\n    validation: Dataset({\n        features: ['__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 167\n    })\n    test: Dataset({\n        features: ['__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 167\n    })\n})"
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:23:08.130506Z",
     "start_time": "2024-05-19T17:23:01.227651Z"
    }
   },
   "execution_count": 323
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lm_datasets = lm_datasets.remove_columns([\"__index_level_0__\", \"token_type_ids\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:23:12.804014Z",
     "start_time": "2024-05-19T17:23:12.782252Z"
    }
   },
   "execution_count": 324
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:23:21.083131Z",
     "start_time": "2024-05-19T17:23:21.066032Z"
    }
   },
   "execution_count": 325
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "        \n",
    "    res = default_data_collator(features)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:23:28.793820Z",
     "start_time": "2024-05-19T17:23:28.774744Z"
    }
   },
   "execution_count": 326
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This was the method used, not the for loops that will appear below\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(lm_datasets[\"train\"]) // batch_size\n",
    "# logging_steps = 1\n",
    "model_name = f\"{model_checkpoint}-wwm\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_checkpoint}-wmm\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_steps=logging_steps,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=8,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:23:40.560471Z",
     "start_time": "2024-05-19T17:23:40.445309Z"
    }
   },
   "execution_count": 329
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load local model\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_m,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    "    test_dataset=lm_datasets[\"test\"],\n",
    "    # data_collator=data_collator,\n",
    "    data_collator=whole_word_masking_data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T15:55:08.545289Z",
     "start_time": "2024-05-19T15:55:08.529737Z"
    }
   },
   "execution_count": 265
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T15:55:08.991587Z",
     "start_time": "2024-05-19T15:55:08.973446Z"
    }
   },
   "execution_count": 266
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def insert_random_mask(batch):\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    masked_inputs = data_collator(features)\n",
    "    # masked_inputs = whole_word_masking_data_collator(features)\n",
    "    \n",
    "    # Create a new \"masked\" column for each column in the dataset\n",
    "    return {\"masked_\" + k: v.numpy() for k, v in masked_inputs.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:23:51.597593Z",
     "start_time": "2024-05-19T17:23:51.577489Z"
    }
   },
   "execution_count": 330
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/167 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c81eb8bb3e7241689dc4b328011512b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = lm_datasets.remove_columns([\"word_ids\"])\n",
    "eval_dataset = lm_datasets[\"validation\"].map(\n",
    "    insert_random_mask,\n",
    "    batched=True,\n",
    "    remove_columns=lm_datasets[\"validation\"].column_names,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:24:07.219085Z",
     "start_time": "2024-05-19T17:24:06.994711Z"
    }
   },
   "execution_count": 332
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_dataset = eval_dataset.rename_columns(\n",
    "    {\n",
    "        \"masked_input_ids\": \"input_ids\",\n",
    "        \"masked_attention_mask\": \"attention_mask\",\n",
    "        \"masked_labels\": \"labels\",\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:24:13.980029Z",
     "start_time": "2024-05-19T17:24:13.964466Z"
    }
   },
   "execution_count": 333
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 167\n})"
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T17:24:14.703626Z",
     "start_time": "2024-05-19T17:24:14.688708Z"
    }
   },
   "execution_count": 334
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import torch_default_data_collator\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "collator = default_data_collator\n",
    "# collator = whole_word_masking_data_collator\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    lm_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, batch_size=batch_size, collate_fn=default_data_collator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:25:11.928935Z",
     "start_time": "2024-05-19T18:25:11.907847Z"
    }
   },
   "execution_count": 353
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1320\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 167\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# lm_datasets[\"validation\"].features\n",
    "print(train_dataloader.dataset)\n",
    "print(eval_dataloader.dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:25:14.540771Z",
     "start_time": "2024-05-19T18:25:14.525630Z"
    }
   },
   "execution_count": 354
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model_m.parameters(), lr=4e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:05:07.420243Z",
     "start_time": "2024-05-19T18:05:07.400156Z"
    }
   },
   "execution_count": 349
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 8\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:25:20.723302Z",
     "start_time": "2024-05-19T18:25:20.711752Z"
    }
   },
   "execution_count": 355
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/168 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5dcd6f0771d4bafaf0ecd3c5f7d5206"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 1: Training Perplexity: 1.0016015851285005\n",
      ">>> Epoch 1: Perplexity: 28291.66003866716\n",
      ">>> Epoch 2: Training Perplexity: 1.0017305385592177\n",
      ">>> Epoch 2: Perplexity: 18920.612252451443\n",
      ">>> Epoch 3: Training Perplexity: 1.0008708001809226\n",
      ">>> Epoch 3: Perplexity: 30854.916717727923\n",
      ">>> Epoch 4: Training Perplexity: 1.0004474036828919\n",
      ">>> Epoch 4: Perplexity: 33737.87399734711\n",
      ">>> Epoch 5: Training Perplexity: 1.0003026585428925\n",
      ">>> Epoch 5: Perplexity: 38197.62142543441\n",
      ">>> Epoch 6: Training Perplexity: 1.0003180343121076\n",
      ">>> Epoch 6: Perplexity: 48887.474472099966\n",
      ">>> Epoch 7: Training Perplexity: 1.0002184581205678\n",
      ">>> Epoch 7: Perplexity: 50281.94303011594\n",
      ">>> Epoch 8: Training Perplexity: 1.0002276090000621\n",
      ">>> Epoch 8: Perplexity: 49376.646908227136\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import math\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "output_dir = f\"{model_name}-wwm\"\n",
    "\n",
    "# this was not the method used for training but the results were essentially the same?? But I had some doubts about the loss/perplexity here\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model_m.train()\n",
    "    training_losses = []\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model_m(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        training_losses.append(loss.repeat(batch_size)) \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    training_losses = torch.cat(training_losses)  # this seems useless and confusing, but wtv\n",
    "    training_losses = training_losses[: len(train_dataloader.dataset)]\n",
    "    try:\n",
    "        training_perplexity = math.exp(torch.mean(training_losses))\n",
    "    except OverflowError:\n",
    "        training_perplexity = float(\"inf\")\n",
    "    print(f\">>> Epoch {epoch + 1}: Training Perplexity: {training_perplexity}\")\n",
    "        \n",
    "\n",
    "    # Evaluation\n",
    "    model_m.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model_m(**batch)\n",
    "\n",
    "        loss:torch.Tensor = outputs.loss\n",
    "        losses.append(loss.repeat(batch_size))\n",
    "\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "\n",
    "    print(f\">>> Epoch {epoch + 1}: Perplexity: {perplexity}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T19:52:00.513857Z",
     "start_time": "2024-05-19T18:25:27.626759Z"
    }
   },
   "execution_count": 357
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/167 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25cb444de314491faa9e9359ebe0f3d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the model\n",
    "# use the test dataset and the whole_word_masking_data_collator\n",
    "test_dataset = lm_datasets[\"test\"].map(\n",
    "    insert_random_mask,\n",
    "    batched=True,\n",
    "    remove_columns=lm_datasets[\"test\"].column_names,\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.rename_columns(\n",
    "    {\n",
    "        \"masked_input_ids\": \"input_ids\",\n",
    "        \"masked_attention_mask\": \"attention_mask\",\n",
    "        \"masked_labels\": \"labels\",\n",
    "    })\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, collate_fn=default_data_collator\n",
    ")\n",
    "\n",
    "# test_dataloader = accelerator.prepare(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T19:53:46.341289Z",
     "start_time": "2024-05-19T19:53:46.176289Z"
    }
   },
   "execution_count": 358
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 167\n})"
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T16:49:29.399805Z",
     "start_time": "2024-05-19T16:49:29.378802Z"
    }
   },
   "execution_count": 296
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import math\n",
    "losses = []\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_m(**batch)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    losses.append(loss.repeat(batch_size))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T19:54:23.192567Z",
     "start_time": "2024-05-19T19:54:13.818771Z"
    }
   },
   "execution_count": 359
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "losses = torch.cat(losses)\n",
    "losses = losses[: len(test_dataset)]\n",
    "try:\n",
    "    perplexity = math.exp(torch.mean(losses))\n",
    "except OverflowError:\n",
    "    perplexity = float(\"inf\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T19:54:28.146883Z",
     "start_time": "2024-05-19T19:54:28.133880Z"
    }
   },
   "execution_count": 360
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Perplexity: 54452.582913266815\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Perplexity: {perplexity}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T19:54:28.887778Z",
     "start_time": "2024-05-19T19:54:28.875784Z"
    }
   },
   "execution_count": 361
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> I am feeling better right now, because of the weather.'\n",
      "'>>> I am feeling bad right now, because of the weather.'\n",
      "'>>> I am feeling good right now, because of the weather.'\n",
      "'>>> I am feeling sick right now, because of the weather.'\n",
      "'>>> I am feeling strange right now, because of the weather.'\n"
     ]
    }
   ],
   "source": [
    "# test on some input\n",
    "text = \"I am feeling [MASK] right now, because of the weather.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "token_logits = model_m(**inputs).logits\n",
    "# Find the location of [MASK] and extract its logits\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "# Pick the [MASK] candidates with the highest logits\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T19:54:32.914412Z",
     "start_time": "2024-05-19T19:54:32.670408Z"
    }
   },
   "execution_count": 362
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save model_m\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T19:56:40.014559Z",
     "start_time": "2024-05-19T19:56:38.094264Z"
    }
   },
   "execution_count": 363
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
